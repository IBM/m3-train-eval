[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:01,676 >> loading file vocab.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/vocab.json
[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:01,677 >> loading file merges.txt from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/merges.txt
[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:01,677 >> loading file tokenizer.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/tokenizer.json
[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:01,677 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:01,677 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:01,677 >> loading file tokenizer_config.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:01,677 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2299] 2025-07-12 18:11:01,964 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:698] 2025-07-12 18:11:02,164 >> loading configuration file config.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/config.json
[INFO|configuration_utils.py:770] 2025-07-12 18:11:02,172 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 12288,
  "max_position_embeddings": 40960,
  "max_window_layers": 36,
  "model_type": "qwen3",
  "num_attention_heads": 32,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:02,241 >> loading file vocab.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/vocab.json
[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:02,241 >> loading file merges.txt from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/merges.txt
[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:02,241 >> loading file tokenizer.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/tokenizer.json
[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:02,241 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:02,241 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:02,241 >> loading file tokenizer_config.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2023] 2025-07-12 18:11:02,241 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2299] 2025-07-12 18:11:02,502 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:698] 2025-07-12 18:11:02,569 >> loading configuration file config.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/config.json
[INFO|configuration_utils.py:770] 2025-07-12 18:11:02,571 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 12288,
  "max_position_embeddings": 40960,
  "max_window_layers": 36,
  "model_type": "qwen3",
  "num_attention_heads": 32,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|modeling_utils.py:1151] 2025-07-12 18:11:03,617 >> loading weights file model.safetensors from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/model.safetensors.index.json
[INFO|modeling_utils.py:2241] 2025-07-12 18:11:03,622 >> Instantiating Qwen3ForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1135] 2025-07-12 18:11:03,624 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:06<00:24,  6.03s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:12<00:18,  6.08s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:18<00:12,  6.06s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:22<00:05,  5.53s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.21s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.96s/it]
[INFO|modeling_utils.py:5131] 2025-07-12 18:11:28,732 >> All model checkpoint weights were used when initializing Qwen3ForCausalLM.

[INFO|modeling_utils.py:5139] 2025-07-12 18:11:28,732 >> All the weights of Qwen3ForCausalLM were initialized from the model checkpoint at Qwen/Qwen3-8B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen3ForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1090] 2025-07-12 18:11:28,794 >> loading configuration file generation_config.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-12 18:11:28,795 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.6,
  "top_k": 20,
  "top_p": 0.95
}

Environment instance:   0%|          | 0/27 [00:00<?, ?it/s]Environment instance:   4%|▎         | 1/27 [00:00<00:09,  2.79it/s]Environment instance:   7%|▋         | 2/27 [00:00<00:07,  3.33it/s]Environment instance:  11%|█         | 3/27 [00:00<00:05,  4.10it/s]Environment instance:  15%|█▍        | 4/27 [00:01<00:05,  3.95it/s]Environment instance:  19%|█▊        | 5/27 [00:01<00:05,  4.39it/s]Environment instance:  22%|██▏       | 6/27 [00:01<00:04,  4.76it/s][WARNING|configuration_utils.py:839] 2025-07-12 18:11:45,009 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:11:45,009 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:11:54,795 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:11:54,795 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:12:02,891 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:12:02,891 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:12:10,985 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:12:10,986 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:12:19,560 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:12:19,561 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:12:27,765 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:12:27,765 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:12:36,579 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:12:36,579 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:12:45,005 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:12:45,006 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:12:54,052 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:12:54,052 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:13:02,368 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:13:02,368 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  26%|██▌       | 7/27 [01:26<09:20, 28.04s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:13:10,365 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:13:10,365 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:13:17,214 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:13:17,214 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:13:23,871 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:13:23,871 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:13:30,127 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:13:30,127 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  30%|██▉       | 8/27 [01:56<09:04, 28.64s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:13:40,288 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:13:40,288 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:13:53,739 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:13:53,739 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:14:08,350 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:14:08,350 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:14:23,366 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:14:23,366 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:14:37,497 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:14:37,497 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:14:52,637 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:14:52,637 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:15:02,980 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:15:02,981 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:15:12,709 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:15:12,710 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:15:22,486 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:15:22,486 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:15:32,295 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:15:32,295 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  33%|███▎      | 9/27 [03:58<17:20, 57.80s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:15:42,203 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:15:42,203 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:15:49,316 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:15:49,316 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:15:56,869 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:15:56,869 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:16:03,887 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:16:03,888 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:16:10,956 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:16:10,956 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:16:17,946 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:16:17,946 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:16:25,231 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:16:25,231 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:16:32,561 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:16:32,561 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:16:39,805 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:16:39,805 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:16:47,267 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:16:47,267 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  37%|███▋      | 10/27 [05:10<17:38, 62.28s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:16:54,518 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:16:54,518 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:17:02,861 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:17:02,861 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|logging.py:328] 2025-07-12 18:17:08,398 >> This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (40960). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.
[WARNING|configuration_utils.py:839] 2025-07-12 18:20:02,063 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:20:02,063 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:23:00,415 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:23:00,415 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:25:59,096 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:25:59,096 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:28:57,763 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:28:57,763 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:31:57,256 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:31:57,256 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:34:56,363 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:34:56,363 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:37:55,131 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:37:55,131 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:40:53,422 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:40:53,422 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  41%|████      | 11/27 [32:08<2:23:33, 538.37s/it]Environment instance:  44%|████▍     | 12/27 [32:08<1:33:39, 374.65s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:43:52,552 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:43:52,552 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:43:59,074 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:43:59,074 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:44:05,614 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:44:05,614 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:44:12,157 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:44:12,157 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:44:19,007 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:44:19,007 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:44:25,634 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:44:25,634 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:44:32,247 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:44:32,247 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:44:38,910 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:44:38,910 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:44:45,766 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:44:45,766 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:44:52,796 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:44:52,796 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  48%|████▊     | 13/27 [33:16<1:05:40, 281.50s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:44:59,783 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:44:59,783 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:45:08,173 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:45:08,173 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:45:13,705 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:45:13,705 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  52%|█████▏    | 14/27 [33:34<43:47, 202.13s/it]  [WARNING|configuration_utils.py:839] 2025-07-12 18:45:18,435 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:45:18,435 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:45:25,559 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:45:25,559 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:45:32,873 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:45:32,873 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:45:40,222 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:45:40,222 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:45:47,706 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:45:47,706 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:45:55,485 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:45:55,485 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:46:03,239 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:46:03,239 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:46:10,924 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:46:10,924 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:46:18,419 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:46:18,419 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:46:25,933 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:46:25,933 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  56%|█████▌    | 15/27 [34:50<32:46, 163.87s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:46:33,654 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:46:33,654 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:46:43,768 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:46:43,768 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:46:53,902 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:46:53,902 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:47:02,130 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:47:02,130 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:47:08,622 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:47:08,623 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:47:15,098 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:47:15,098 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:47:21,528 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:47:21,528 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:47:28,147 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:47:28,147 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:47:34,933 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:47:34,933 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:47:41,751 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:47:41,751 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  59%|█████▉    | 16/27 [36:05<25:08, 137.16s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:47:48,817 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:47:48,818 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:47:57,923 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:47:57,923 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:48:07,231 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:48:07,231 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:48:16,642 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:48:16,642 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:48:25,732 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:48:25,732 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:48:34,892 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:48:34,892 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:48:44,079 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:48:44,079 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:48:53,315 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:48:53,315 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:49:02,672 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:49:02,672 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:49:12,060 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:49:12,060 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  63%|██████▎   | 17/27 [37:37<20:37, 123.71s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:49:21,328 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:49:21,328 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:49:32,669 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:49:32,670 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:49:41,452 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:49:41,452 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:49:51,370 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:49:51,370 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:50:00,161 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:50:00,161 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:50:09,865 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:50:09,866 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:50:19,106 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:50:19,106 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:50:28,921 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:50:28,921 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:50:38,309 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:50:38,309 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:50:48,345 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:50:48,345 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  67%|██████▋   | 18/27 [39:13<17:19, 115.46s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:50:57,470 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:50:57,470 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:51:03,421 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:51:03,421 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:51:09,162 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:51:09,162 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:51:14,932 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:51:14,932 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:51:20,968 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:51:20,968 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:51:26,808 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:51:26,808 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:51:32,665 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:51:32,665 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:51:38,560 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:51:38,560 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:51:44,553 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:51:44,553 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:51:50,605 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:51:50,605 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  70%|███████   | 19/27 [40:13<13:09, 98.72s/it] [WARNING|configuration_utils.py:839] 2025-07-12 18:51:57,296 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:51:57,296 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:52:05,932 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:52:05,932 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:52:17,027 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:52:17,027 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:52:27,797 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:52:27,797 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:52:38,511 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:52:38,511 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:52:49,515 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:52:49,515 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:53:00,476 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:53:00,476 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:53:11,674 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:53:11,674 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:53:23,281 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:53:23,281 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:53:34,385 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:53:34,385 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  74%|███████▍  | 20/27 [42:02<11:51, 101.69s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:53:45,877 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:53:45,877 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:53:52,876 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:53:52,876 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:53:59,047 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:53:59,047 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  78%|███████▊  | 21/27 [42:25<07:49, 78.18s/it] Environment instance:  81%|████████▏ | 22/27 [42:25<04:33, 54.79s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:54:09,479 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:54:09,479 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:54:15,952 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:54:15,952 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:54:21,405 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:54:21,406 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  85%|████████▌ | 23/27 [42:52<03:04, 46.21s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:54:35,677 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:54:35,677 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:54:43,253 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:54:43,253 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:54:54,545 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:54:54,545 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:55:07,153 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:55:07,153 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:55:20,192 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:55:20,192 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:55:33,980 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:55:33,980 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:55:46,580 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:55:46,580 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:55:59,365 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:55:59,365 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:56:12,058 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:56:12,058 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:56:24,991 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:56:24,991 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  89%|████████▉ | 24/27 [44:54<03:27, 69.12s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:56:38,141 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:56:38,141 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:56:54,805 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:56:54,805 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:57:06,473 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:57:06,473 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:57:18,444 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:57:18,445 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:57:30,468 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:57:30,468 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:57:42,210 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:57:42,210 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:57:54,301 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:57:54,301 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:58:06,660 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:58:06,660 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:58:18,542 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:58:18,542 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:58:30,427 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:58:30,427 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  93%|█████████▎| 25/27 [46:58<02:51, 85.65s/it][WARNING|configuration_utils.py:839] 2025-07-12 18:58:42,371 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:58:42,371 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:58:51,882 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:58:51,882 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:58:58,801 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:58:58,802 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:59:06,539 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:59:06,540 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:59:17,647 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:59:17,647 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:59:25,138 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:59:25,138 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:59:35,163 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:59:35,163 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:59:44,786 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:59:44,786 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 18:59:54,842 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 18:59:54,842 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
[WARNING|configuration_utils.py:839] 2025-07-12 19:00:04,112 >> The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k'].
[INFO|configuration_utils.py:840] 2025-07-12 19:00:04,112 >> - `temperature`: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
- `top_p`: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
- `top_k`: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.
If you're using a pretrained model, note that some of these attributes may be set through the model's `generation_config.json` file.
Environment instance:  96%|█████████▋| 26/27 [48:31<01:27, 87.72s/it]Environment instance: 100%|██████████| 27/27 [48:31<00:00, 61.49s/it]Environment instance: 100%|██████████| 27/27 [48:31<00:00, 107.84s/it]
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,180 >> loading file vocab.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/vocab.json
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,180 >> loading file merges.txt from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/merges.txt
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,180 >> loading file tokenizer.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/tokenizer.json
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,180 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,180 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,180 >> loading file tokenizer_config.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,180 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2299] 2025-07-12 19:00:15,469 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:698] 2025-07-12 19:00:15,677 >> loading configuration file config.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/config.json
[INFO|configuration_utils.py:770] 2025-07-12 19:00:15,678 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 12288,
  "max_position_embeddings": 40960,
  "max_window_layers": 36,
  "model_type": "qwen3",
  "num_attention_heads": 32,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,759 >> loading file vocab.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/vocab.json
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,759 >> loading file merges.txt from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/merges.txt
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,760 >> loading file tokenizer.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/tokenizer.json
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,760 >> loading file added_tokens.json from cache at None
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,760 >> loading file special_tokens_map.json from cache at None
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,760 >> loading file tokenizer_config.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/tokenizer_config.json
[INFO|tokenization_utils_base.py:2023] 2025-07-12 19:00:15,760 >> loading file chat_template.jinja from cache at None
[INFO|tokenization_utils_base.py:2299] 2025-07-12 19:00:16,050 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|configuration_utils.py:698] 2025-07-12 19:00:16,130 >> loading configuration file config.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/config.json
[INFO|configuration_utils.py:770] 2025-07-12 19:00:16,130 >> Model config Qwen3Config {
  "architectures": [
    "Qwen3ForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 151643,
  "eos_token_id": 151645,
  "head_dim": 128,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 12288,
  "max_position_embeddings": 40960,
  "max_window_layers": 36,
  "model_type": "qwen3",
  "num_attention_heads": 32,
  "num_hidden_layers": 36,
  "num_key_value_heads": 8,
  "rms_norm_eps": 1e-06,
  "rope_scaling": null,
  "rope_theta": 1000000,
  "sliding_window": null,
  "tie_word_embeddings": false,
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.4",
  "use_cache": true,
  "use_sliding_window": false,
  "vocab_size": 151936
}

[INFO|modeling_utils.py:1151] 2025-07-12 19:00:16,136 >> loading weights file model.safetensors from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/model.safetensors.index.json
[INFO|modeling_utils.py:2241] 2025-07-12 19:00:16,141 >> Instantiating Qwen3ForCausalLM model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1135] 2025-07-12 19:00:16,144 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "eos_token_id": 151645
}

Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:06<00:24,  6.12s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:12<00:17,  5.99s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:17<00:11,  5.90s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:22<00:05,  5.45s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:24<00:00,  4.93s/it]
[INFO|modeling_utils.py:5131] 2025-07-12 19:00:41,182 >> All model checkpoint weights were used when initializing Qwen3ForCausalLM.

[INFO|modeling_utils.py:5139] 2025-07-12 19:00:41,182 >> All the weights of Qwen3ForCausalLM were initialized from the model checkpoint at Qwen/Qwen3-8B.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen3ForCausalLM for predictions without further training.
[INFO|configuration_utils.py:1090] 2025-07-12 19:00:41,239 >> loading configuration file generation_config.json from cache at /u/aj05/project/hf_cache/hub/models--Qwen--Qwen3-8B/snapshots/9c925d64d72725edaf899c6cb9c377fd0709d9c5/generation_config.json
[INFO|configuration_utils.py:1135] 2025-07-12 19:00:41,239 >> Generate config GenerationConfig {
  "bos_token_id": 151643,
  "do_sample": true,
  "eos_token_id": [
    151645,
    151643
  ],
  "pad_token_id": 151643,
  "temperature": 0.6,
  "top_k": 20,
  "top_p": 0.95
}

Traceback (most recent call last):
  File "/u/aj05/project/Code/run.py", line 320, in <module>
    run_agent()
  File "/u/aj05/project/Code/run.py", line 112, in run_agent
    agent = get_agent(
            ^^^^^^^^^^
  File "/u/aj05/project/Code/agents/loader.py", line 60, in get_agent
    llm = get_lm_hf(hf_config=hf_config)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/aj05/project/Code/agents/llm.py", line 134, in get_lm_hf
    model = load_model(tokenizer, model_args, finetuning_args, is_trainable=False)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/aj05/project/Code/model/loader.py", line 185, in load_model
    model = init_adapter(config, model, model_args, finetuning_args, is_trainable)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/aj05/project/Code/model/adapter.py", line 319, in init_adapter
    model = _setup_lora_tuning(
            ^^^^^^^^^^^^^^^^^^^
  File "/u/aj05/project/Code/model/adapter.py", line 202, in _setup_lora_tuning
    model: LoraModel = PeftModel.from_pretrained(model, adapter, **init_kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/aj05/miniconda3/envs/AgenticAI/lib/python3.11/site-packages/peft/peft_model.py", line 555, in from_pretrained
    load_result = model.load_adapter(
                  ^^^^^^^^^^^^^^^^^^^
  File "/u/aj05/miniconda3/envs/AgenticAI/lib/python3.11/site-packages/peft/peft_model.py", line 1323, in load_adapter
    load_result = set_peft_model_state_dict(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/aj05/miniconda3/envs/AgenticAI/lib/python3.11/site-packages/peft/utils/save_and_load.py", line 455, in set_peft_model_state_dict
    load_result = model.load_state_dict(peft_model_state_dict, strict=False)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/u/aj05/miniconda3/envs/AgenticAI/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2593, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for PeftModelForCausalLM:
	size mismatch for base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.28.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.28.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.28.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.29.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.29.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.29.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.30.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.30.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.30.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.31.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.31.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.31.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.32.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.32.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.32.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.33.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.33.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.33.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.34.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.34.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.34.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
	size mismatch for base_model.model.model.layers.35.mlp.gate_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.35.mlp.up_proj.lora_B.default.weight: copying a param with shape torch.Size([12800, 64]) from checkpoint, the shape in current model is torch.Size([12288, 64]).
	size mismatch for base_model.model.model.layers.35.mlp.down_proj.lora_A.default.weight: copying a param with shape torch.Size([64, 12800]) from checkpoint, the shape in current model is torch.Size([64, 12288]).
